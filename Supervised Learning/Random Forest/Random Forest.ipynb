{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Random Forest.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMf9NJXKJaC2vhTLhSf7Bd5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vtGVVdrHMTG8"},"source":["# Importing the libraries"]},{"cell_type":"code","metadata":{"id":"NYGfsnyiMUp8"},"source":["import numpy as np\n","\n","from math import log2, sqrt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import metrics\n","from sklearn import tree\n","from sklearn import preprocessing\n","import matplotlib.pyplot as plt\n","import six\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import export_graphviz\n","from six import StringIO  \n","from IPython.display import Image  \n","import pydotplus\n","from tqdm.notebook import tqdm_notebook as tqdm\n","from sklearn.model_selection import GridSearchCV\n","\n","# Implementation from \"Decision Trees.ipynb\"\n","from decision_tree import MyDecisionTree"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMh0nWVtOCn5"},"source":["# Exploring the Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"zBsujFUxOD2s","executionInfo":{"status":"ok","timestamp":1636291327517,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ofir Gilad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVQ5-KDUcXOndwUIl3ITIftawvt4VjCyo0uDRZ=s64","userId":"11248672105255574895"}},"outputId":"4a03dc6d-b5ac-406c-8e1c-87feb2167e0d"},"source":["columns_names = ['age', 'workclass', 'fnlwg', 'education', 'education_num', 'marital_status',\n","                 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week',\n","                 'country', 'target']\n","df_train = pd.read_csv(\"adult_data.csv\", header = None, names = columns_names)\n","df_train.drop(columns=\"fnlwg\", inplace=True)\n","df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>education_num</th>\n","      <th>marital_status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital_gain</th>\n","      <th>capital_loss</th>\n","      <th>hours_per_week</th>\n","      <th>country</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age          workclass   education  ...  hours_per_week         country  target\n","0   39          State-gov   Bachelors  ...              40   United-States   <=50K\n","1   50   Self-emp-not-inc   Bachelors  ...              13   United-States   <=50K\n","2   38            Private     HS-grad  ...              40   United-States   <=50K\n","3   53            Private        11th  ...              40   United-States   <=50K\n","4   28            Private   Bachelors  ...              40            Cuba   <=50K\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"-96oMJhBOG6K","executionInfo":{"status":"ok","timestamp":1636291327791,"user_tz":-120,"elapsed":277,"user":{"displayName":"Ofir Gilad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVQ5-KDUcXOndwUIl3ITIftawvt4VjCyo0uDRZ=s64","userId":"11248672105255574895"}},"outputId":"cc38f78a-9a0f-45a4-c3ab-40b9fae8945d"},"source":["columns_names = ['age', 'workclass', 'fnlwg', 'education', 'education_num', 'marital_status',\n","                 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week',\n","                 'country', 'target']\n","df_test = pd.read_csv(\"adult_test.csv\", header = None, names = columns_names)\n","df_test.drop(columns=\"fnlwg\", inplace=True)\n","df_test = df_test.iloc[1:, :]\n","df_test['age'] = pd.to_numeric(df_test['age'])\n","df_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>workclass</th>\n","      <th>education</th>\n","      <th>education_num</th>\n","      <th>marital_status</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capital_gain</th>\n","      <th>capital_loss</th>\n","      <th>hours_per_week</th>\n","      <th>country</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>25</td>\n","      <td>Private</td>\n","      <td>11th</td>\n","      <td>7.0</td>\n","      <td>Never-married</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Own-child</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>40.0</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>HS-grad</td>\n","      <td>9.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Farming-fishing</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>50.0</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>28</td>\n","      <td>Local-gov</td>\n","      <td>Assoc-acdm</td>\n","      <td>12.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Protective-serv</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>40.0</td>\n","      <td>United-States</td>\n","      <td>&gt;50K.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>44</td>\n","      <td>Private</td>\n","      <td>Some-college</td>\n","      <td>10.0</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>7688.0</td>\n","      <td>0.0</td>\n","      <td>40.0</td>\n","      <td>United-States</td>\n","      <td>&gt;50K.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>18</td>\n","      <td>?</td>\n","      <td>Some-college</td>\n","      <td>10.0</td>\n","      <td>Never-married</td>\n","      <td>?</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age   workclass      education  ...  hours_per_week         country   target\n","1   25     Private           11th  ...            40.0   United-States   <=50K.\n","2   38     Private        HS-grad  ...            50.0   United-States   <=50K.\n","3   28   Local-gov     Assoc-acdm  ...            40.0   United-States    >50K.\n","4   44     Private   Some-college  ...            40.0   United-States    >50K.\n","5   18           ?   Some-college  ...            30.0   United-States   <=50K.\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"pFvsK1c9hnhB"},"source":["X_train = df_train.iloc[:, :-1]\n","y_train = df_train.iloc[:, -1]\n","label_enc = LabelEncoder()\n","y_train = label_enc.fit_transform(y_train)\n","\n","X_test = df_test.iloc[:, :-1]\n","y_test = df_test.iloc[:, -1]\n","label_enc = LabelEncoder()\n","y_test = label_enc.fit_transform(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yn_8_dKxdB05"},"source":["# Random Forest Implementation"]},{"cell_type":"code","metadata":{"id":"aNF4zWnddCsk"},"source":["class RandomForest(object):\n","    def __init__(self, n_estimators=50, max_depth=None, max_features=0.7):\n","        # How many estimators we are going to use?\n","        self.n_estimators = n_estimators\n","        # Max depth\n","        self.max_depth = max_depth\n","        # The percentage of the RANDOM features we are going to use\n","        self.max_features = max_features\n","        # Which examples are in the current bootstrap\n","        self.bootstraps_row_indices = []\n","        # Keeping track of features indices\n","        self.feature_indices = []\n","        # To calculate the out of bag error\n","        self.out_of_bag = []\n","        \n","        decision_trees = []\n","        for i in range(n_estimators):\n","            # Call our DT class\n","            decision_trees.append(MyDecisionTree(max_depth=max_depth))\n","        # Our random forest\n","        self.decision_trees = decision_trees\n","        # Or self.decision_trees = [MyDecisionTree(max_depth=max_depth) for i in range(n_estimators)]\n","        \n","    def _bootstrapping(self, num_training, num_features): ## _ is similar to private in other programming language\n","        \"\"\"\n","        - INPUT : \n","            num_training: how many training examples in this bootstrap\n","            num_features: how many features in this bootstrap\n","            \n","        - OUTPUT :\n","        - row_idx: the row indices corresponding to the row locations of the selected samples in the original dataset.\n","        - col_idx: the column indices corresponding to the column locations of the selected features  \n","                   in the original feature list.\n","        \n","        \n","        \n","        - Randomly select a sample dataset of size num_training with replacement from the original dataset. \n","        - Randomly select certain number of features (num_features denotes the total number of features in X,\n","          without replacement from the total number of features.\n","        \"\"\" \n","        \n","        sample_size = list(range(num_training))\n","        # Create random row indices\n","        row_idx = np.random.choice(sample_size,num_training)\n","        # Permutation (with replacement)\n","        col_idx = np.random.permutation(num_features)[:int(num_features*self.max_features)]\n","        return row_idx, col_idx\n","            \n","    def bootstrapping(self, num_training, num_features):\n","        \"\"\"\n","        Initializing the bootstap datasets for each tree\n","        \"\"\"\n","        \n","        for i in range(self.n_estimators):\n","            # We use a set to get the unique elements\n","            total = set(list(range(num_training)))\n","            row_idx, col_idx = self._bootstrapping(num_training, num_features)\n","            # Again we use a set. Subtract the row indices from the total\n","            total = total - set(row_idx)\n","            self.bootstraps_row_indices.append(row_idx)\n","            self.feature_indices.append(col_idx)\n","            # Total is used for the OOB\n","            self.out_of_bag.append(total) \n","            \n","            \n","    def fit(self, X, y):\n","        \"\"\"\n","        Train decision trees using the bootstrapped datasets.\n","        \"\"\"\n","        \n","        num_training, num_features = X.shape\n","        # Initialize the bootstrapping\n","        self.bootstrapping(num_training,num_features)\n","        # Loop over the trees \n","        for i in range(self.n_estimators):\n","            current_bootstraps_row_indices = self.bootstraps_row_indices[i]\n","            current_feature_indices = self.feature_indices[i]\n","            current_X = X[current_bootstraps_row_indices[:,np.newaxis], current_feature_indices] ## data for this tree\n","            current_y = y[current_bootstraps_row_indices]\n","            current_dt = self.decision_trees[i]\n","            # 0 for the initial depth\n","            current_dt.fit(current_X,current_y, 0)\n","            # Which tree we are using\n","            print(\"Current Tree to fit : \" ,i+1)\n","            \n","            \n","    def OOB_score(self, X, y):\n","        \"\"\"\n","        Calculate the OOB score\n","        \"\"\"\n","        \n","        accuracy = []\n","        # Loop over the full dataset\n","        for i in range(len(X)):\n","            predictions = []\n","            # Loop over each decision tree\n","            for t in range(self.n_estimators):\n","                # The data that is NOT used in the current tree\n","                if i in self.out_of_bag[t]:\n","                    # Predict\n","                    predictions.append(self.decision_trees[t].predict(X[i][self.feature_indices[t]]))\n","            if len(predictions) > 0:\n","                # Majority voting\n","                accuracy.append(np.sum(predictions == y[i]) / float(len(predictions)))\n","        # Total accuracy\n","        return np.mean(accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dQDH7PzeEmh"},"source":["# Evaluate the Random Forest"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6A35EileGyb","executionInfo":{"status":"ok","timestamp":1636291621512,"user_tz":-120,"elapsed":208779,"user":{"displayName":"Ofir Gilad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVQ5-KDUcXOndwUIl3ITIftawvt4VjCyo0uDRZ=s64","userId":"11248672105255574895"}},"outputId":"1eb83c4d-f3db-4623-ffa2-330d0c2c1926"},"source":["n_estimators = 3\n","max_depth = 7\n","max_features = 0.8\n","X_train = np.array(X_train)\n","X_test = np.array(X_test)\n","random_forest = RandomForest(n_estimators, max_depth, max_features)\n","\n","random_forest.fit(X_train, y_train)\n","accuracy=random_forest.OOB_score(X_test, y_test)\n","\n","print(\"accuracy: %.4f\" % accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current Tree to fit :  1\n","Current Tree to fit :  2\n","Current Tree to fit :  3\n","accuracy: 0.7943\n"]}]},{"cell_type":"code","metadata":{"id":"XNbM4Li8lxVM"},"source":["X_train = df_train.iloc[:, :-1]\n","X_test = df_test.iloc[:, :-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLT0PCPJlGP4","executionInfo":{"status":"ok","timestamp":1636291799409,"user_tz":-120,"elapsed":6318,"user":{"displayName":"Ofir Gilad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVQ5-KDUcXOndwUIl3ITIftawvt4VjCyo0uDRZ=s64","userId":"11248672105255574895"}},"outputId":"2e30294b-b91d-410f-8082-b19e59928bbd"},"source":["X_train_encoded = pd.get_dummies(X_train, drop_first=True)\n","X_train_encoded.drop(columns = \"country_ Holand-Netherlands\", inplace = True)\n","\n","X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n","clf = RandomForestClassifier()\n","clf.fit(X_train_encoded, y_train)\n","y_pred = clf.predict(X_test_encoded)\n","print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8459554081444629\n"]}]},{"cell_type":"markdown","metadata":{"id":"SQgcOlH4qlln"},"source":["# Random Forest Pros and Cons"]},{"cell_type":"markdown","metadata":{"id":"NAhdO1yEqp6-"},"source":["\n","| Pros | Cons\n","| --- | --- \n","|Robust to outliers| biased while dealing with categorical variables.\n","|Works well with non-linear data.|Slow Training if the code isn't optimized.\n","|Lower risk of overfitting.|Not suitable for linear methods with a lot of sparse features\n","|Runs efficiently on a large dataset.|Greedy algorithms donâ€™t yield the global optimum tree structure.\n","\n"]}]}